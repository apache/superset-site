(window.webpackJsonp=window.webpackJsonp||[]).push([[22],{bBR2:function(e,t,n){"use strict";n.r(t),n.d(t,"_frontmatter",(function(){return c})),n.d(t,"default",(function(){return b}));var a=n("k1TG"),o=n("8o2o"),s=(n("q1tI"),n("7ljp")),i=n("hhGP"),c=(n("qKvR"),{});void 0!==c&&c&&c===Object(c)&&Object.isExtensible(c)&&!c.hasOwnProperty("__filemeta")&&Object.defineProperty(c,"__filemeta",{configurable:!0,value:{name:"_frontmatter",filename:"src/pages/docs/Connecting to Databases/elasticsearch.mdx"}});var r={_frontmatter:c},l=i.a;function b(e){var t=e.components,n=Object(o.a)(e,["components"]);return Object(s.b)(l,Object(a.a)({},r,n,{components:t,mdxType:"MDXLayout"}),Object(s.b)("h2",{id:"elasticsearch"},"Elasticsearch"),Object(s.b)("p",null,"The recommended connector library for Elasticsearch is\n",Object(s.b)("a",Object(a.a)({parentName:"p"},{href:"https://github.com/preset-io/elasticsearch-dbapi"}),"elasticsearch-dbapi"),"."),Object(s.b)("p",null,"The connection string for Elasticsearch looks like this:"),Object(s.b)("pre",null,Object(s.b)("code",Object(a.a)({parentName:"pre"},{}),"elasticsearch+http://{user}:{password}@{host}:9200/\n")),Object(s.b)("p",null,Object(s.b)("strong",{parentName:"p"},"Using HTTPS")),Object(s.b)("pre",null,Object(s.b)("code",Object(a.a)({parentName:"pre"},{}),"elasticsearch+https://{user}:{password}@{host}:9200/\n")),Object(s.b)("p",null,"Elasticsearch as a default limit of 10000 rows, so you can increase this limit on your cluster or\nset Supersetâ€™s row limit on config"),Object(s.b)("pre",null,Object(s.b)("code",Object(a.a)({parentName:"pre"},{}),"ROW_LIMIT = 10000\n")),Object(s.b)("p",null,"You can query multiple indices on SQL Lab for example"),Object(s.b)("pre",null,Object(s.b)("code",Object(a.a)({parentName:"pre"},{}),'SELECT timestamp, agent FROM "logstash"\n')),Object(s.b)("p",null,"But, to use visualizations for multiple indices you need to create an alias index on your cluster"),Object(s.b)("pre",null,Object(s.b)("code",Object(a.a)({parentName:"pre"},{}),'POST /_aliases\n{\n    "actions" : [\n        { "add" : { "index" : "logstash-**", "alias" : "logstash_all" } }\n    ]\n}\n')),Object(s.b)("p",null,"Then register your table with the alias name logstasg_all"),Object(s.b)("p",null,Object(s.b)("strong",{parentName:"p"},"Time zone")),Object(s.b)("p",null,"By default, Superset uses UTC time zone for elasticsearch query. If you need to specify a time zone,\nplease edit your Database and enter the settings of your specified time zone in the Other > ENGINE PARAMETERS:"),Object(s.b)("pre",null,Object(s.b)("code",Object(a.a)({parentName:"pre"},{}),'{\n    "connect_args": {\n        "time_zone": "Asia/Shanghai"\n    }\n}\n')),Object(s.b)("p",null,"Another issue to note about the time zone problem is that before elasticsearch7.8, if you want to convert a string into a ",Object(s.b)("inlineCode",{parentName:"p"},"DATETIME")," object,\nyou need to use the ",Object(s.b)("inlineCode",{parentName:"p"},"CAST")," function,but this function does not support our ",Object(s.b)("inlineCode",{parentName:"p"},"time_zone")," setting. So it is recommended to upgrade to the version after elasticsearch7.8.\nAfter elasticsearch7.8, you can use the ",Object(s.b)("inlineCode",{parentName:"p"},"DATETIME_PARSE")," function to solve this problem.\nThe DATETIME_PARSE function is to support our ",Object(s.b)("inlineCode",{parentName:"p"},"time_zone")," setting, and here you need to fill in your elasticsearch version number in the Other > VERSION setting.\nthe superset will use the ",Object(s.b)("inlineCode",{parentName:"p"},"DATETIME_PARSE")," function for conversion."))}void 0!==b&&b&&b===Object(b)&&Object.isExtensible(b)&&!b.hasOwnProperty("__filemeta")&&Object.defineProperty(b,"__filemeta",{configurable:!0,value:{name:"MDXContent",filename:"src/pages/docs/Connecting to Databases/elasticsearch.mdx"}}),b.isMDXComponent=!0}}]);
//# sourceMappingURL=component---src-pages-docs-connecting-to-databases-elasticsearch-mdx-e17344a42e2bdaf21dcb.js.map