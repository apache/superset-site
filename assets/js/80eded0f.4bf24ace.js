"use strict";(self.webpackChunkdocs_v_2=self.webpackChunkdocs_v_2||[]).push([[5209],{33248:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>a,contentTitle:()=>o,default:()=>h,frontMatter:()=>t,metadata:()=>c,toc:()=>l});var s=r(74848),i=r(28453);const t={title:"Async Queries via Celery",hide_title:!0,sidebar_position:4,version:1},o="Async Queries via Celery",c={id:"configuration/async-queries-celery",title:"Async Queries via Celery",description:"Celery",source:"@site/docs/configuration/async-queries-celery.mdx",sourceDirName:"configuration",slug:"/configuration/async-queries-celery",permalink:"/docs/configuration/async-queries-celery",draft:!1,unlisted:!1,editUrl:"https://github.com/apache/superset/edit/master/docs/docs/configuration/async-queries-celery.mdx",tags:[],version:"current",sidebarPosition:4,frontMatter:{title:"Async Queries via Celery",hide_title:!0,sidebar_position:4,version:1},sidebar:"CustomSidebar",previous:{title:"Caching",permalink:"/docs/configuration/cache"},next:{title:"SQL Templating",permalink:"/docs/configuration/sql-templating"}},a={},l=[{value:"Celery",id:"celery",level:2},{value:"Celery Flower",id:"celery-flower",level:2}];function d(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h1,{id:"async-queries-via-celery",children:"Async Queries via Celery"}),"\n",(0,s.jsx)(n.h2,{id:"celery",children:"Celery"}),"\n",(0,s.jsx)(n.p,{children:"On large analytic databases, it\u2019s common to run queries that execute for minutes or hours. To enable\nsupport for long running queries that execute beyond the typical web request\u2019s timeout (30-60\nseconds), it is necessary to configure an asynchronous backend for Superset which consists of:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["one or many Superset workers (which is implemented as a Celery worker), and can be started with\nthe ",(0,s.jsx)(n.code,{children:"celery worker"})," command, run ",(0,s.jsx)(n.code,{children:"celery worker --help"})," to view the related options."]}),"\n",(0,s.jsx)(n.li,{children:"a celery broker (message queue) for which we recommend using Redis or RabbitMQ"}),"\n",(0,s.jsx)(n.li,{children:"a results backend that defines where the worker will persist the query results"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Configuring Celery requires defining a ",(0,s.jsx)(n.code,{children:"CELERY_CONFIG"})," in your ",(0,s.jsx)(n.code,{children:"superset_config.py"}),". Both the worker\nand web server processes should have the same configuration."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'class CeleryConfig(object):\n    broker_url = "redis://localhost:6379/0"\n    imports = (\n        "superset.sql_lab",\n        "superset.tasks.scheduler",\n    )\n    result_backend = "redis://localhost:6379/0"\n    worker_prefetch_multiplier = 10\n    task_acks_late = True\n    task_annotations = {\n        "sql_lab.get_sql_results": {\n            "rate_limit": "100/s",\n        },\n    }\n\nCELERY_CONFIG = CeleryConfig\n'})}),"\n",(0,s.jsx)(n.p,{children:"To start a Celery worker to leverage the configuration, run the following command:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"celery --app=superset.tasks.celery_app:app worker --pool=prefork -O fair -c 4\n"})}),"\n",(0,s.jsx)(n.p,{children:"To start a job which schedules periodic background jobs, run the following command:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"celery --app=superset.tasks.celery_app:app beat\n"})}),"\n",(0,s.jsxs)(n.p,{children:["To setup a result backend, you need to pass an instance of a derivative of from\nfrom flask_caching.backends.base import BaseCache to the RESULTS_BACKEND configuration key in your superset_config.py. You can\nuse Memcached, Redis, S3 (",(0,s.jsx)(n.a,{href:"https://pypi.python.org/pypi/s3werkzeugcache",children:"https://pypi.python.org/pypi/s3werkzeugcache"}),"), memory or the file system\n(in a single server-type setup or for testing), or to write your own caching interface. Your\n",(0,s.jsx)(n.code,{children:"superset_config.py"})," may look something like:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# On S3\nfrom s3cache.s3cache import S3Cache\nS3_CACHE_BUCKET = 'foobar-superset'\nS3_CACHE_KEY_PREFIX = 'sql_lab_result'\nRESULTS_BACKEND = S3Cache(S3_CACHE_BUCKET, S3_CACHE_KEY_PREFIX)\n\n# On Redis\nfrom flask_caching.backends.rediscache import RedisCache\nRESULTS_BACKEND = RedisCache(\n    host='localhost', port=6379, key_prefix='superset_results')\n"})}),"\n",(0,s.jsxs)(n.p,{children:["For performance gains, ",(0,s.jsx)(n.a,{href:"https://github.com/msgpack/msgpack-python",children:"MessagePack"})," and\n",(0,s.jsx)(n.a,{href:"https://arrow.apache.org/docs/python/",children:"PyArrow"})," are now used for results serialization. This can be\ndisabled by setting ",(0,s.jsx)(n.code,{children:"RESULTS_BACKEND_USE_MSGPACK = False"})," in your ",(0,s.jsx)(n.code,{children:"superset_config.py"}),", should any\nissues arise. Please clear your existing results cache store when upgrading an existing environment."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Important Notes"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["It is important that all the worker nodes and web servers in the Superset cluster ",(0,s.jsx)(n.em,{children:"share a common\nmetadata database"}),". This means that SQLite will not work in this context since it has limited\nsupport for concurrency and typically lives on the local file system."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["There should ",(0,s.jsx)(n.em,{children:"only be one instance of celery beat running"})," in your entire setup. If not,\nbackground jobs can get scheduled multiple times resulting in weird behaviors like duplicate\ndelivery of reports, higher than expected load / traffic etc."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["SQL Lab will ",(0,s.jsx)(n.em,{children:"only run your queries asynchronously if"})," you enable ",(0,s.jsx)(n.strong,{children:"Asynchronous Query Execution"}),"\nin your database settings (Sources > Databases > Edit record)."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"celery-flower",children:"Celery Flower"}),"\n",(0,s.jsx)(n.p,{children:"Flower is a web based tool for monitoring the Celery cluster which you can install from pip:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"pip install flower\n"})}),"\n",(0,s.jsx)(n.p,{children:"You can run flower using:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"celery --app=superset.tasks.celery_app:app flower\n"})})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},28453:(e,n,r)=>{r.d(n,{R:()=>o,x:()=>c});var s=r(96540);const i={},t=s.createContext(i);function o(e){const n=s.useContext(t);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);